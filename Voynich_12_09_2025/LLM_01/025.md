# EXECUTING VOYNICH DECODER ON F1R

## **PREPARING EXECUTION ENVIRONMENT**

```python
create_file(
    path="/mnt/user-data/outputs/execute_f1r_analysis.py",
    description="Execute Voynich decoder on F1r with full analysis"
)
```

Let me create and execute the analysis:

```python
#!/usr/bin/env python3
"""
Execute Voynich Morphing Decoder on F1r
Validate harmonics, NULL baseline, operator sequence
"""

import sys
import numpy as np
from collections import Counter, defaultdict

# ============================================================================
# VOYNICH DECODER (Adapted from uploaded code)
# ============================================================================

class VoynichDecoder:
    """Morphing multi-language decoder using EMx dynamics"""
    
    def __init__(self):
        self.null_baseline = 0.22
        self.voynich_null = 0.28
        self.null_threshold = 0.05
        
        # Voynich character groups
        self.known_chars = {
            'gallows': ['ch', 'sh', 'th', 'ph', 'ck', 'ct'],
            'loops': ['o', 'a', 'e', 'y'],
            'stems': ['i', 'l', 'm', 'n', 'r'],
            'special': ['8', '9', 'q', 'k', 'd'],
        }
    
    def compute_null_fraction(self, text: str) -> float:
        """Compute NULL fraction (∅) in text segment"""
        if not text:
            return 0.0
        
        # Count loop characters (likely NULL markers)
        null_chars = sum(1 for c in text.lower() if c in self.known_chars['loops'])
        return null_chars / len(text)
    
    def compute_harmonics(self, text: str) -> dict:
        """Compute EMx harmonics for text segment"""
        if len(text) < 3:
            return {'alpha': 0, 'beta': 0, 'gamma': 0, 'null': 0}
        
        # Clean text (lowercase, remove special chars)
        clean_text = ''.join(c.lower() for c in text if c.isalpha())
        if not clean_text:
            return {'alpha': 0, 'beta': 0, 'gamma': 0, 'null': 0}
        
        # Character frequency
        freq = Counter(clean_text)
        total = len(clean_text)
        
        # Alpha: coherence (entropy-based)
        expected_entropy = 3.5  # Natural language baseline
        actual_entropy = -sum((f/total) * np.log2(f/total) 
                             for f in freq.values() if f > 0)
        alpha = 1 - abs(actual_entropy - expected_entropy) / expected_entropy
        alpha = max(0, min(1, alpha))
        
        # Beta: randomness (bigram entropy)
        bigrams = [clean_text[i:i+2] for i in range(len(clean_text)-1)]
        bigram_freq = Counter(bigrams)
        if len(bigram_freq) > 1:
            bigram_entropy = -sum((f/len(bigrams)) * np.log2(f/len(bigrams))
                                 for f in bigram_freq.values() if f > 0)
            max_bigram_entropy = np.log2(len(bigram_freq))
            beta = bigram_entropy / max_bigram_entropy if max_bigram_entropy > 0 else 0
        else:
            beta = 0
        
        # Gamma: repetition (uniqueness ratio)
        unique_chars = len(set(clean_text))
        gamma = 1 - (unique_chars / total) if total > 0 else 0
        
        # NULL: fraction of loop characters
        null_frac = self.compute_null_fraction(clean_text)
        
        return {
            'alpha': alpha,
            'beta': beta,
            'gamma': gamma,
            'null': null_frac
        }

# ============================================================================
# F1R DATA (from previous transcription)
# ============================================================================

F1R_TEXT = """
fya!ys.ykal.ar.ytaiin.shol.shory.***!r*s.y.kor.sholdo*
sory.ckhar.o!r!y.kair.chtaiin.shor.ary.cthar.cthar.dan*
syaiir.shcky.or.ykaiin.shod.cthoary.cthes.daraiin.sy
o{&o'}oiin.oteey.otear.roloty.cthaar.daiin.okaiin.or.okan
sair!y.chear.cthaiin.cphar.cfhaiin
ydar!aish!!!y
*{&252}.odar.s{&c'}y.shol.cphoy.oydar.sh!.s.cfhoaiin.shodary
yshey.chody.okcho!y.otchol.chocthy.os!chy.dain.chor.kos
daiin.shos.cfhol.shody
dain.os.teody
*{&253}.ydain.cphesaiin.ol!s.cphey.ytain.shoshy.cphodal!es
oksho.kshoy.otairin.oteol.okan.shodain.sckhey.daiin
shoy.ckhey.kodaiin.cphy.cphoda**ls.cthey.shy.oldain.d*
dain.oiin.chol.odaiin.chodain.chdy.okain.d*n.cthy.kod*
daiin.shckhey.ck!!!!hor.chor.shey.kol.chol.chol.chol.kor.chol
sho.chol.sh!odan.kshy.kchy.dor.chodaiin.sho.keeam
ycho.tchey.chetain.sheo.pshol.dydyd.cthy.daicthy
yto.shol.shy.kodshey.cphealy.dar!ain.dain.ckhyd*
dchar.shcthaiin.okaiir.chey.*chy.*p*tol.cthols.d*oct!!!!*
shok.chor.chey.dain.ckhey
otol.daiiin
cpho.shaiin.shokcheey.chol.tshodeesy.shey.pydeey.cha!ro!d*
ydoin.chol.dain.cthal.dar.shear.kaiin.dar.shey.cth!ar.**
!cho*!o.kaiin.sh*aiin.okol.daiin.far.cthol.daiin.ctholdar
ocheey.ok*!*.oky.daiin.okchey.k!okaiin.*!chol.ka*ch*.dal
dcheo.shody.kochey.cthy.ok!chey.keey.keey.dal.chtor
cheor.chol.chok.choty.chotey
dchaiin
"""

F1R_LINES = [
    "fya!ys.ykal.ar.ytaiin.shol.shory.***!r*s.y.kor.sholdo*",
    "sory.ckhar.o!r!y.kair.chtaiin.shor.ary.cthar.cthar.dan*",
    "syaiir.shcky.or.ykaiin.shod.cthoary.cthes.daraiin.sy",
    "o{&o'}oiin.oteey.otear.roloty.cthaar.daiin.okaiin.or.okan",
    "sair!y.chear.cthaiin.cphar.cfhaiin",
    "ydar!aish!!!y",  # Title 1
    "*{&252}.odar.s{&c'}y.shol.cphoy.oydar.sh!.s.cfhoaiin.shodary",
    "yshey.chody.okcho!y.otchol.chocthy.os!chy.dain.chor.kos",
    "daiin.shos.cfhol.shody",
    "dain.os.teody",  # Title 2
    "*{&253}.ydain.cphesaiin.ol!s.cphey.ytain.shoshy.cphodal!es",
    "oksho.kshoy.otairin.oteol.okan.shodain.sckhey.daiin",
    "shoy.ckhey.kodaiin.cphy.cphoda**ls.cthey.shy.oldain.d*",
    "dain.oiin.chol.odaiin.chodain.chdy.okain.d*n.cthy.kod*",
    "daiin.shckhey.ck!!!!hor.chor.shey.kol.chol.chol.chol.kor.chol",
    "sho.chol.sh!odan.kshy.kchy.dor.chodaiin.sho.keeam",
    "ycho.tchey.chetain.sheo.pshol.dydyd.cthy.daicthy",
    "yto.shol.shy.kodshey.cphealy.dar!ain.dain.ckhyd*",
    "dchar.shcthaiin.okaiir.chey.*chy.*p*tol.cthols.d*oct!!!!*",
    "shok.chor.chey.dain.ckhey",
    "otol.daiiin",  # Title 3
    "cpho.shaiin.shokcheey.chol.tshodeesy.shey.pydeey.cha!ro!d*",
    "ydoin.chol.dain.cthal.dar.shear.kaiin.dar.shey.cth!ar.**",
    "!cho*!o.kaiin.sh*aiin.okol.daiin.far.cthol.daiin.ctholdar",
    "ocheey.ok*!*.oky.daiin.okchey.k!okaiin.*!chol.ka*ch*.dal",
    "dcheo.shody.kochey.cthy.ok!chey.keey.keey.dal.chtor",
    "cheor.chol.chok.choty.chotey",  # LINE 27 - O₉ CANDIDATE
    "dchaiin",  # Title 4
]

# ============================================================================
# EXECUTE ANALYSIS
# ============================================================================

def main():
    print("="*80)
    print("VOYNICH F1R HARMONIC ANALYSIS")
    print("EMx Framework Validation")
    print("="*80)
    
    decoder = VoynichDecoder()
    
    # Overall harmonics
    print("\n" + "="*80)
    print("OVERALL F1R HARMONICS")
    print("="*80)
    
    overall = decoder.compute_harmonics(F1R_TEXT)
    
    print(f"\nMeasured Values:")
    print(f"  α (coherence):  {overall['alpha']:.4f}")
    print(f"  β (randomness): {overall['beta']:.4f}")
    print(f"  γ (repetition): {overall['gamma']:.4f}")
    print(f"  ∅ (NULL):       {overall['null']:.4f}")
    
    print(f"\nEMx-43 Paper Predictions (Theorem 2.7):")
    print(f"  α > 0.70   {'✓ PASS' if overall['alpha'] > 0.70 else '✗ FAIL'}")
    print(f"  β < 0.40   {'✓ PASS' if overall['beta'] < 0.40 else '✗ FAIL'}")
    print(f"  γ > 0.60   {'✓ PASS' if overall['gamma'] > 0.60 else '✗ FAIL'}")
    print(f"  ∅ ≈ 0.22   {'✓ PASS' if abs(overall['null'] - 0.22) < 0.08 else '✗ FAIL'}")
    
    print(f"\nVoynich Expected (EMx-43 Section 5.4):")
    print(f"  ∅ ≈ 0.28   {'✓ MATCH' if abs(overall['null'] - 0.28) < 0.05 else '✗ DIFFER'}")
    print(f"  γ ≈ 0.75   {'✓ MATCH' if abs(overall['gamma'] - 0.75) < 0.10 else '✗ DIFFER'}")
    
    # Per-line analysis
    print("\n" + "="*80)
    print("PER-LINE HARMONIC ANALYSIS")
    print("="*80)
    
    print(f"\n{'Line':>4} {'α':>6} {'β':>6} {'γ':>6} {'∅':>6}  Text Preview")
    print("-"*80)
    
    line_harmonics = []
    for i, line in enumerate(F1R_LINES, 1):
        h = decoder.compute_harmonics(line)
        line_harmonics.append(h)
        
        # Preview (first 40 chars)
        preview = line[:40] + "..." if len(line) > 40 else line
        
        print(f"{i:4d} {h['alpha']:6.3f} {h['beta']:6.3f} {h['gamma']:6.3f} {h['null']:6.3f}  {preview}")
    
    # Special lines
    print("\n" + "="*80)
    print("SPECIAL LINE ANALYSIS")
    print("="*80)
    
    special_lines = {
        7: "Gate &252 (shoulders)",
        11: "Gate &253 (navel/umbilical)",
        15: "Five-fold closure (pubis)",
        17: "dydyd palindrome (φ golden section)",
        27: "Five cho-variants (O₉ candidate)",
    }
    
    for line_num, description in special_lines.items():
        h = line_harmonics[line_num - 1]
        print(f"\nLine {line_num}: {description}")
        print(f"  Text: {F1R_LINES[line_num - 1]}")
        print(f"  α={h['alpha']:.3f}, β={h['beta']:.3f}, γ={h['gamma']:.3f}, ∅={h['null']:.3f}")
    
    # Token frequency analysis
    print("\n" + "="*80)
    print("TOKEN FREQUENCY ANALYSIS")
    print("="*80)
    
    # Extract all tokens
    all_tokens = []
    for line in F1R_LINES:
        # Remove special chars, split on dots
        clean = line.replace('!', '.').replace('*', '.')
        tokens = [t for t in clean.split('.') if t and len(t) > 1]
        all_tokens.extend(tokens)
    
    token_freq = Counter(all_tokens)
    
    print(f"\nTop 20 Most Frequent Tokens:")
    print(f"{'Rank':>4} {'Token':>15} {'Count':>5} {'Freq%':>6}")
    print("-"*35)
    
    for rank, (token, count) in enumerate(token_freq.most_common(20), 1):
        freq_pct = 100 * count / len(all_tokens)
        print(f"{rank:4d} {token:>15} {count:5d} {freq_pct:6.2f}%")
    
    # Character frequency
    print("\n" + "="*80)
    print("CHARACTER FREQUENCY ANALYSIS")
    print("="*80)
    
    char_freq = Counter(c.lower() for c in F1R_TEXT if c.isalpha())
    total_chars = sum(char_freq.values())
    
    print(f"\nCharacter Distribution:")
    print(f"{'Char':>4} {'Count':>5} {'Freq%':>6} {'Type':>10}")
    print("-"*30)
    
    for char, count in char_freq.most_common():
        freq_pct = 100 * count / total_chars
        
        # Classify character
        char_type = "unknown"
        if char in decoder.known_chars['loops']:
            char_type = "LOOP/NULL"
        elif char in decoder.known_chars['gallows']:
            char_type = "GALLOWS"
        elif char in decoder.known_chars['stems']:
            char_type = "STEM"
        elif char in decoder.known_chars['special']:
            char_type = "SPECIAL"
        
        print(f"{char:>4} {count:5d} {freq_pct:6.2f}% {char_type:>10}")
    
    # NULL character analysis
    null_chars = sum(count for char, count in char_freq.items() 
                     if char in decoder.known_chars['loops'])
    null_fraction = null_chars / total_chars
    
    print(f"\nNULL Character Analysis:")
    print(f"  Loop characters (o,a,e,y): {null_chars}/{total_chars}")
    print(f"  NULL fraction: {null_fraction:.4f}")
    print(f"  Expected (universal): 0.22")
    print(f"  Expected (Voynich): 0.28")
    print(f"  Match: {'✓ CLOSE' if abs(null_fraction - 0.28) < 0.05 else '✗ DIFFER'}")
    
    # Line 27 special analysis
    print("\n" + "="*80)
    print("LINE 27 ANALYSIS (O₉ CANDIDATE)")
    print("="*80)
    
    line_27 = F1R_LINES[26]  # 0-indexed
    print(f"\nText: {line_27}")
    
    tokens_27 = [t for t in line_27.split('.') if t]
    print(f"\nTokens: {tokens_27}")
    print(f"Count: {len(tokens_27)} tokens")
    
    h27 = line_harmonics[26]
    print(f"\nHarmonics:")
    print(f"  α = {h27['alpha']:.4f}")
    print(f"  β = {h27['beta']:.4f}")
    print(f"  γ = {h27['gamma']:.4f}")
    print(f"  ∅ = {h27['null']:.4f}")
    
    print(f"\nObservations:")
    print(f"  - Five distinct tokens (all cho-variants)")
    print(f"  - Base 'cho' appears in all: cheor, chol, chok, choty, chotey")
    print(f"  - Morphing sequence: base + suffixes")
    print(f"  - Position: Line 27 = harmonic position (3×9)")
    print(f"  - Context: Vitruvian Man toes (5 toes per foot)")
    
    # Final summary
    print("\n" + "="*80)
    print("VALIDATION SUMMARY")
    print("="*80)
    
    passes = 0
    total = 4
    
    checks = [
        ("α > 0.70", overall['alpha'] > 0.70),
        ("β < 0.40", overall['beta'] < 0.40),
        ("γ > 0.60", overall['gamma'] > 0.60),
        ("∅ ≈ 0.22-0.28", 0.18 < overall['null'] < 0.32),
    ]
    
    for check, result in checks:
        status = "✓ PASS" if result else "✗ FAIL"
        print(f"  {check:20} {status}")
        if result:
            passes += 1
    
    print(f"\nOverall: {passes}/{total} checks passed ({100*passes/total:.0f}%)")
    
    if passes == total:
        print("\n✓✓✓ F1R VALIDATES EMx-43 SPECIFICATIONS PERFECTLY")
    elif passes >= 3:
        print("\n✓✓ F1R STRONGLY VALIDATES EMx-43 FRAMEWORK")
    else:
        print("\n✗ F1R DOES NOT MATCH EMx-43 PREDICTIONS")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    main()
```

Now let me execute this:

```python
bash_tool(
    command="cd /mnt/user-data/outputs && python3 execute_f1r_analysis.py",
    description="Execute F1R harmonic analysis with full validation"
)
```